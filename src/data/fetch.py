#!/usr/bin/env python3
"""Fetch bghira/pseudo-camera-10k images and captions to paired JSONL."""
import argparse
import json
import os
from pathlib import Path

from rich.console import Console
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, BarColumn, TextColumn, MofNCompleteColumn
from rich.table import Table

os.environ.setdefault("HF_HUB_DOWNLOAD_TIMEOUT", "120")
os.environ.setdefault("HF_HUB_DOWNLOAD_WORKERS", "4")

DATA_DIR = os.environ.get("DATA_DIR", "/data")
REPO_ID = "bghira/pseudo-camera-10k"

console = Console()


def fetch_pseudo_camera(num_samples: int, output_file: str):
    from huggingface_hub import snapshot_download

    console.print(Panel(
        "[bold]bghira/pseudo-camera-10k[/bold]\n\n"
        "~10K synthetic photographs with detailed captions generated by SDXL + LLaVA.\n"
        "Each sample is a PNG image paired with a text caption describing the scene.\n"
        "Used for vision-language model fine-tuning (image captioning / visual QA).",
        title="Dataset",
        expand=False,
    ))

    # Check for HF token (authenticated requests get much higher rate limits)
    hf_token = os.environ.get("HF_TOKEN")
    if not hf_token or hf_token == "your_token_here":
        console.print("[yellow]Warning:[/yellow] No HF_TOKEN set. "
                      "Downloads may be rate-limited. Set it in secrets.env.")
    else:
        console.print("Using HF_TOKEN for authenticated downloads")

    # Download both images and captions in one snapshot (parallel, cached)
    workers = int(os.environ.get("HF_HUB_DOWNLOAD_WORKERS", "4"))
    console.print(f"Downloading from HuggingFace (train/*.png + caption/*.txt, {workers} workers)...")
    local_dir = snapshot_download(
        REPO_ID,
        repo_type="dataset",
        allow_patterns=["train/*.png", "caption/*.txt"],
        token=hf_token if hf_token and hf_token != "your_token_here" else None,
    )

    image_dir = Path(local_dir) / "train"
    caption_dir = Path(local_dir) / "caption"

    image_files = {f.stem: f for f in image_dir.glob("*.png")}
    caption_files = {f.stem: f for f in caption_dir.glob("*.txt")}

    # Match by filename stem (images and captions share the same stem)
    common_stems = sorted(set(image_files) & set(caption_files))
    console.print(
        f"Found [bold]{len(image_files)}[/bold] images, "
        f"[bold]{len(caption_files)}[/bold] captions, "
        f"[bold]{len(common_stems)}[/bold] matched pairs"
    )

    if not common_stems:
        raise ValueError("No matched image-caption pairs found")

    # Show a few sample captions so the user can see what the data looks like
    sample_table = Table(title="Sample Captions", show_lines=True, expand=False)
    sample_table.add_column("Image", style="cyan", no_wrap=True)
    sample_table.add_column("Caption", max_width=100)
    for stem in common_stems[:3]:
        caption = caption_files[stem].read_text(encoding="utf-8").strip()
        preview = caption[:120] + "..." if len(caption) > 120 else caption
        sample_table.add_row(f"{stem}.png", preview)
    console.print(sample_table)

    output_path = Path(output_file)
    output_path.parent.mkdir(parents=True, exist_ok=True)

    total = min(len(common_stems), num_samples) if num_samples else len(common_stems)
    saved = 0
    skipped = 0

    with open(output_path, "w", encoding="utf-8") as fout, \
         Progress(
             SpinnerColumn(),
             TextColumn("[progress.description]{task.description}"),
             BarColumn(),
             MofNCompleteColumn(),
             TextColumn("[dim]{task.fields[status]}[/dim]"),
             console=console,
         ) as progress:
        task = progress.add_task("Pairing images+captions", total=total, status="")
        for stem in common_stems:
            if num_samples and saved >= num_samples:
                break

            caption = caption_files[stem].read_text(encoding="utf-8").strip()
            if not caption:
                skipped += 1
                progress.advance(task)
                progress.update(task, status=f"skipped {skipped}")
                continue

            record = {
                "image": str(image_files[stem]),
                "caption": caption,
            }
            json.dump(record, fout, ensure_ascii=False)
            fout.write("\n")
            saved += 1
            progress.advance(task)

    console.print(
        f"Saved [bold green]{saved}[/bold green] image-caption pairs "
        f"to {output_file} (skipped {skipped} empty)"
    )


def main():
    parser = argparse.ArgumentParser(description="Fetch pseudo-camera-10k image-caption pairs")
    parser.add_argument(
        "--samples", type=int,
        default=int(os.environ.get("DATA_SAMPLES", 10000)),
        help="Max number of pairs to fetch (default: DATA_SAMPLES env or 10K)",
    )
    parser.add_argument(
        "--output", type=str,
        default=f"{DATA_DIR}/pseudo-camera-raw.jsonl",
        help="Output JSONL file path",
    )
    args = parser.parse_args()
    fetch_pseudo_camera(args.samples, args.output)


if __name__ == "__main__":
    main()
